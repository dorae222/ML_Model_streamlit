{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3a37ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.5.1\n",
      "matplotlib version: 3.5.1\n",
      "NumPy version: 1.22.4\n",
      "SciPy version: 1.7.3\n",
      "IPython version: 8.2.0\n",
      "scikit-learn version: 1.0.2\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f070fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91bbea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data_raw = pd.read_csv('titanic_train.csv', index_col=0)\n",
    "data_val  = pd.read_csv('titanic_test.csv', index_col=0)\n",
    "data1 = data_raw.copy(deep = True)\n",
    "data_cleaner = [data1, data_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d4ce8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수업시간에 쓴 전처리 코드를 그대로 가져왔습니다.\n",
    "def pre_processing(df : pd.DataFrame):\n",
    "    try:\n",
    "        df.Embarked = df.Embarked.fillna(\"S\")\n",
    "        df.Fare = df.Fare.fillna(0)\n",
    "        df['Title'] = df.Name.str.extract('([A-Za-z]+)\\.')\n",
    "        rarelist = [a for a in set(df['Title'])\n",
    "                    if list(df['Title']).count(a) < 10]\n",
    "        df['Title'] = df['Title'].replace(rarelist, 'Rare')\n",
    "        title_age_mean = df.groupby(['Title'])['Age'].mean()\n",
    "        for v in df['Title'].unique():\n",
    "            df.loc[df.Age.isnull() & (df.Title == v), 'Age'] = title_age_mean[v]\n",
    "        df_clean = df.drop(columns=['Name', 'Ticket', 'Title', 'Cabin'])\n",
    "        return pd.get_dummies(df_clean,\n",
    "                              columns = ['Sex', 'Embarked'], drop_first=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36d1bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pre_processing(data_raw)\n",
    "test = pre_processing(data_val)\n",
    "data1 = pre_processing(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dd7f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y:  ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "for dataset in data_cleaner:    \n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "\n",
    "\n",
    "#define y variable aka target/outcome\n",
    "Target = ['Survived']\n",
    "\n",
    "#define x variables for original features aka feature selection\n",
    "data1_x = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','Sex_male','Embarked_Q','Embarked_S'] #pretty name/values for charts\n",
    "data1_x_calc = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','Sex_male','Embarked_Q','Embarked_S'] #coded for algorithm calculation\n",
    "data1_xy =  Target + data1_x\n",
    "print('Original X Y: ', data1_xy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec74eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin X Y:  ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define x variables for original w/bin features to remove continuous variables\n",
    "data1_x_bin = ['Pclass','Age', 'SibSp', 'Parch', 'Fare','Sex_male','Embarked_Q','Embarked_S']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a52bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy X Y:  ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "0       3  22.0      1      0   7.2500         1           0           1\n",
       "1       1  38.0      1      0  71.2833         0           0           0\n",
       "2       3  26.0      0      0   7.9250         0           0           1\n",
       "3       1  35.0      1      0  53.1000         0           0           1\n",
       "4       3  35.0      0      0   8.0500         1           0           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define x and y variables for dummy features original\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')\n",
    "\n",
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c86c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 Shape: (891, 9)\n",
      "Train1 Shape: (668, 8)\n",
      "Test1 Shape: (223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  Embarked_S\n",
       "105       3  28.0      0      0   7.8958         1           0           1\n",
       "68        3  17.0      4      2   7.9250         0           0           1\n",
       "253       3  30.0      1      0  16.1000         1           0           1\n",
       "320       3  22.0      0      0   7.2500         1           0           1\n",
       "706       2  45.0      0      0  13.5000         0           0           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\n",
    "train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target] , random_state = 0)\n",
    "train1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)\n",
    "\n",
    "\n",
    "print(\"Data1 Shape: {}\".format(data1.shape))\n",
    "print(\"Train1 Shape: {}\".format(train1_x.shape))\n",
    "print(\"Test1 Shape: {}\".format(test1_x.shape))\n",
    "\n",
    "train1_x_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a7ac2bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.912547</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>0.062366</td>\n",
       "      <td>0.086712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.978839</td>\n",
       "      <td>0.816791</td>\n",
       "      <td>0.08458</td>\n",
       "      <td>0.082256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.971161</td>\n",
       "      <td>0.814925</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.019514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.98633</td>\n",
       "      <td>0.814925</td>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.162768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.808955</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>0.058293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.81161</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.049063</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>0.808801</td>\n",
       "      <td>0.801866</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.462154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.804869</td>\n",
       "      <td>0.797015</td>\n",
       "      <td>0.052313</td>\n",
       "      <td>0.005226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>0.80412</td>\n",
       "      <td>0.796269</td>\n",
       "      <td>0.052313</td>\n",
       "      <td>0.005562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.98633</td>\n",
       "      <td>0.793284</td>\n",
       "      <td>0.05159</td>\n",
       "      <td>0.112839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.821161</td>\n",
       "      <td>0.792164</td>\n",
       "      <td>0.059665</td>\n",
       "      <td>0.09182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.794569</td>\n",
       "      <td>0.78806</td>\n",
       "      <td>0.063481</td>\n",
       "      <td>0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.785768</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.043122</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.98633</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.061516</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.98633</td>\n",
       "      <td>0.761567</td>\n",
       "      <td>0.061811</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.723408</td>\n",
       "      <td>0.722388</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.725094</td>\n",
       "      <td>0.722015</td>\n",
       "      <td>0.326522</td>\n",
       "      <td>0.022668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.950375</td>\n",
       "      <td>0.719776</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>0.256782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.724906</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.106196</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.789139</td>\n",
       "      <td>0.709701</td>\n",
       "      <td>0.077198</td>\n",
       "      <td>0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.684082</td>\n",
       "      <td>0.676119</td>\n",
       "      <td>0.064848</td>\n",
       "      <td>0.070577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.66161</td>\n",
       "      <td>0.672015</td>\n",
       "      <td>0.165766</td>\n",
       "      <td>0.003662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "3      GradientBoostingClassifier   \n",
       "21                  XGBClassifier   \n",
       "1               BaggingClassifier   \n",
       "4          RandomForestClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "6            LogisticRegressionCV   \n",
       "8               RidgeClassifierCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "2            ExtraTreesClassifier   \n",
       "15                          NuSVC   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "17         DecisionTreeClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "9                   SGDClassifier   \n",
       "16                      LinearSVC   \n",
       "5       GaussianProcessClassifier   \n",
       "7     PassiveAggressiveClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "14                            SVC   \n",
       "10                     Perceptron   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.912547   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...                0.978839   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.971161   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                 0.98633   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                  0.8397   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...                 0.81161   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...                0.808801   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...                0.804869   \n",
       "19  {'covariance_estimator': None, 'n_components':...                 0.80412   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                 0.98633   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...                0.821161   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                0.794569   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.785768   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.98633   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.98633   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...                0.723408   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...                0.725094   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...                0.950375   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...                0.724906   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.789139   \n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...                0.684082   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...                 0.66161   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD  MLA Time  \n",
       "3                0.833582                0.062366  0.086712  \n",
       "21               0.816791                 0.08458  0.082256  \n",
       "1                0.814925                0.054656  0.019514  \n",
       "4                0.814925                0.060737  0.162768  \n",
       "0                0.808955                0.062687  0.058293  \n",
       "20               0.803358                0.049063  0.002232  \n",
       "6                0.801866                0.061404  0.462154  \n",
       "8                0.797015                0.052313  0.005226  \n",
       "19               0.796269                0.052313  0.005562  \n",
       "2                0.793284                 0.05159  0.112839  \n",
       "15               0.792164                0.059665   0.09182  \n",
       "12                0.78806                0.063481  0.001207  \n",
       "11               0.785075                0.043122  0.001912  \n",
       "17               0.779851                0.061516  0.002993  \n",
       "18               0.761567                0.061811  0.002185  \n",
       "9                0.722388                0.168224  0.003458  \n",
       "16               0.722015                0.326522  0.022668  \n",
       "5                0.719776                0.071581  0.256782  \n",
       "7                0.716418                0.106196  0.002552  \n",
       "13               0.709701                0.077198  0.003818  \n",
       "14               0.676119                0.064848  0.070577  \n",
       "10               0.672015                0.165766  0.003662  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier()    \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = data1[Target]\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(data1[data1_x_bin], data1[Target])\n",
    "    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "\n",
    "\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885076fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\n",
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577b8151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE DT Parameters:  {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 0, 'splitter': 'best'}\n",
      "BEFORE DT Training w/bin score mean: 98.63\n",
      "BEFORE DT Test w/bin score mean: 77.80\n",
      "BEFORE DT Test w/bin score 3*std: +/- 6.91\n",
      "----------\n",
      "AFTER DT Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
      "AFTER DT Training w/bin score mean: 89.76\n",
      "AFTER DT Test w/bin score mean: 85.77\n",
      "AFTER DT Test w/bin score 3*std: +/- 7.11\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#base model\n",
    "dtree = tree.DecisionTreeClassifier(random_state = 0)\n",
    "base_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "dtree.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print('BEFORE DT Parameters: ', dtree.get_params())\n",
    "print(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print(\"BEFORE DT Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n",
    "#print(\"BEFORE DT Test w/bin set score min: {:.2f}\". format(base_results['test_score'].min()*100))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#tune hyper-parameters: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n",
    "              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n",
    "              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n",
    "              #'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n",
    "              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n",
    "              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n",
    "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n",
    "             }\n",
    "\n",
    "#print(list(model_selection.ParameterGrid(param_grid)))\n",
    "\n",
    "#choose best model with grid_search: #http://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "#print(tune_model.cv_results_.keys())\n",
    "#print(tune_model.cv_results_['params'])\n",
    "print('AFTER DT Parameters: ', tune_model.best_params_)\n",
    "#print(tune_model.cv_results_['mean_train_score'])\n",
    "print(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n",
    "#print(tune_model.cv_results_['mean_test_score'])\n",
    "print(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#duplicates gridsearchcv\n",
    "#tune_results = model_selection.cross_validate(tune_model, data1[data1_x_bin], data1[Target], cv  = cv_split)\n",
    "\n",
    "#print('AFTER DT Parameters: ', tune_model.best_params_)\n",
    "#print(\"AFTER DT Training w/bin set score mean: {:.2f}\". format(tune_results['train_score'].mean()*100)) \n",
    "#print(\"AFTER DT Test w/bin set score mean: {:.2f}\". format(tune_results['test_score'].mean()*100))\n",
    "#print(\"AFTER DT Test w/bin set score min: {:.2f}\". format(tune_results['test_score'].min()*100))\n",
    "#print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f2a9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE DT RFE Training Shape Old:  (891, 8)\n",
      "BEFORE DT RFE Training Columns Old:  ['Pclass' 'Age' 'SibSp' 'Parch' 'Fare' 'Sex_male' 'Embarked_Q'\n",
      " 'Embarked_S']\n",
      "BEFORE DT RFE Training w/bin score mean: 98.63\n",
      "BEFORE DT RFE Test w/bin score mean: 77.80\n",
      "BEFORE DT RFE Test w/bin score 3*std: +/- 6.91\n",
      "----------\n",
      "AFTER DT RFE Training Shape New:  (891, 5)\n",
      "AFTER DT RFE Training Columns New:  ['Pclass' 'Age' 'SibSp' 'Fare' 'Sex_male']\n",
      "AFTER DT RFE Training w/bin score mean: 98.46\n",
      "AFTER DT RFE Test w/bin score mean: 78.51\n",
      "AFTER DT RFE Test w/bin score 3*std: +/- 4.78\n",
      "----------\n",
      "AFTER DT RFE Tuned Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
      "AFTER DT RFE Tuned Training w/bin score mean: 89.75\n",
      "AFTER DT RFE Tuned Test w/bin score mean: 85.45\n",
      "AFTER DT RFE Tuned Test w/bin score 3*std: +/- 7.66\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#base model\n",
    "print('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \n",
    "print('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n",
    "\n",
    "print(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "\n",
    "#feature selection\n",
    "dtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\n",
    "dtree_rfe.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "#transform x&y to reduced features and fit new model\n",
    "#alternative: can use pipeline to reduce fit and transform steps: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "X_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\n",
    "rfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "\n",
    "#print(dtree_rfe.grid_scores_)\n",
    "print('AFTER DT RFE Training Shape New: ', data1[X_rfe].shape) \n",
    "print('AFTER DT RFE Training Columns New: ', X_rfe)\n",
    "\n",
    "print(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \n",
    "print(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\n",
    "print(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#tune rfe model\n",
    "rfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score=True)\n",
    "rfe_tune_model.fit(data1[X_rfe], data1[Target])\n",
    "\n",
    "#print(rfe_tune_model.cv_results_.keys())\n",
    "#print(rfe_tune_model.cv_results_['params'])\n",
    "print('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n",
    "#print(rfe_tune_model.cv_results_['mean_train_score'])\n",
    "print(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n",
    "#print(rfe_tune_model.cv_results_['mean_test_score'])\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97a5d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Training w/bin score mean: 93.61\n",
      "Hard Voting Test w/bin score mean: 82.09\n",
      "Hard Voting Test w/bin score 3*std: +/- 6.37\n",
      "----------\n",
      "Soft Voting Training w/bin score mean: 94.72\n",
      "Soft Voting Test w/bin score mean: 82.76\n",
      "Soft Voting Test w/bin score 3*std: +/- 8.10\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vote_est = [\n",
    "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "    ('ada', ensemble.AdaBoostClassifier()),\n",
    "    ('bc', ensemble.BaggingClassifier()),\n",
    "    ('etc',ensemble.ExtraTreesClassifier()),\n",
    "    ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "    ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "    #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "    ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "    \n",
    "    #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    ('lr', linear_model.LogisticRegressionCV()),\n",
    "    \n",
    "    #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "    ('bnb', naive_bayes.BernoulliNB()),\n",
    "    ('gnb', naive_bayes.GaussianNB()),\n",
    "    \n",
    "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "    ('knn', neighbors.KNeighborsClassifier()),\n",
    "    \n",
    "    #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "    ('svc', svm.SVC(probability=True)),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "   ('xgb', XGBClassifier())\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "#Hard Vote or majority rules\n",
    "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
    "vote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "vote_hard.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
    "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
    "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#Soft Vote or weighted probabilities\n",
    "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "vote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "vote_soft.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
    "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
    "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862c94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter for AdaBoostClassifier is {'learning_rate': 0.03, 'n_estimators': 300, 'random_state': 0} with a runtime of 39.18 seconds.\n",
      "The best parameter for BaggingClassifier is {'max_samples': 0.5, 'n_estimators': 300, 'random_state': 0} with a runtime of 49.80 seconds.\n",
      "The best parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 300, 'random_state': 0} with a runtime of 66.92 seconds.\n",
      "The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 53.35 seconds.\n",
      "The best parameter for RandomForestClassifier is {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 300, 'oob_score': True, 'random_state': 0} with a runtime of 105.29 seconds.\n",
      "The best parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with a runtime of 14.13 seconds.\n",
      "The best parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'lbfgs'} with a runtime of 31.76 seconds.\n",
      "The best parameter for BernoulliNB is {'alpha': 0.1} with a runtime of 0.30 seconds.\n",
      "The best parameter for GaussianNB is {} with a runtime of 0.03 seconds.\n",
      "The best parameter for KNeighborsClassifier is {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'distance'} with a runtime of 5.80 seconds.\n",
      "The best parameter for SVC is {'C': 3, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0} with a runtime of 71.25 seconds.\n",
      "The best parameter for XGBClassifier is {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'seed': 0} with a runtime of 106.64 seconds.\n",
      "Total optimization time was 9.07 minutes.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "grid_learn = [.01, .03, .05, .1, .25]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_min_samples = [5, 10, .03, .05, .10]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [0]\n",
    "\n",
    "\n",
    "grid_param = [\n",
    "            [{\n",
    "            #AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "            'n_estimators': grid_n_estimator, #default=50\n",
    "            'learning_rate': grid_learn, #default=1\n",
    "            #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R\n",
    "            'random_state': grid_seed\n",
    "            }],\n",
    "       \n",
    "    \n",
    "            [{\n",
    "            #BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "            'n_estimators': grid_n_estimator, #default=10\n",
    "            'max_samples': grid_ratio, #default=1.0\n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "\n",
    "    \n",
    "            [{\n",
    "            #ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "            'n_estimators': grid_n_estimator, #default=10\n",
    "            'criterion': grid_criterion, #default=”gini”\n",
    "            'max_depth': grid_max_depth, #default=None\n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "\n",
    "\n",
    "            [{\n",
    "            #GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "            #'loss': ['deviance', 'exponential'], #default=’deviance’\n",
    "            'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "            'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "            #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse”\n",
    "            'max_depth': grid_max_depth, #default=3   \n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "\n",
    "    \n",
    "            [{\n",
    "            #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "            'n_estimators': grid_n_estimator, #default=10\n",
    "            'criterion': grid_criterion, #default=”gini”\n",
    "            'max_depth': grid_max_depth, #default=None\n",
    "            'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "    \n",
    "            [{    \n",
    "            #GaussianProcessClassifier\n",
    "            'max_iter_predict': grid_n_estimator, #default: 100\n",
    "            'random_state': grid_seed\n",
    "            }],\n",
    "        \n",
    "    \n",
    "            [{\n",
    "            #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "            'fit_intercept': grid_bool, #default: True\n",
    "            #'penalty': ['l1','l2'],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "            \n",
    "    \n",
    "            [{\n",
    "            #BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n",
    "            'alpha': grid_ratio, #default: 1.0\n",
    "             }],\n",
    "    \n",
    "    \n",
    "            #GaussianNB - \n",
    "            [{}],\n",
    "    \n",
    "            [{\n",
    "            #KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "            'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n",
    "            'weights': ['uniform', 'distance'], #default = ‘uniform’\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }],\n",
    "            \n",
    "    \n",
    "            [{\n",
    "            #SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "            #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n",
    "            #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': [1,2,3,4,5], #default=1.0\n",
    "            'gamma': grid_ratio, #edfault: auto\n",
    "            'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n",
    "            'probability': [True],\n",
    "            'random_state': grid_seed\n",
    "             }],\n",
    "\n",
    "    \n",
    "            [{\n",
    "            #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "            'learning_rate': grid_learn, #default: .3\n",
    "            'max_depth': [1,2,4,6,8,10], #default 2\n",
    "            'n_estimators': grid_n_estimator, \n",
    "            'seed': grid_seed  \n",
    "             }]   \n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "start_total = time.perf_counter() #https://docs.python.org/3/library/time.html#time.perf_counter\n",
    "for clf, param in zip (vote_est, grid_param): #https://docs.python.org/3/library/functions.html#zip\n",
    "\n",
    "    #print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm\n",
    "    #print(param)\n",
    "    \n",
    "    \n",
    "    start = time.perf_counter()        \n",
    "    best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'roc_auc')\n",
    "    best_search.fit(data1[data1_x_bin], data1[Target])\n",
    "    run = time.perf_counter() - start\n",
    "\n",
    "    best_param = best_search.best_params_\n",
    "    print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n",
    "    clf[1].set_params(**best_param) \n",
    "\n",
    "\n",
    "run_total = time.perf_counter() - start_total\n",
    "print('Total optimization time was {:.2f} minutes.'.format(run_total/60))\n",
    "\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a53649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 90.49\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.24\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.16\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 92.08\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.72\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 6.21\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Hard Vote or majority rules w/Tuned Hyperparameters\n",
    "grid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
    "grid_hard_cv = model_selection.cross_validate(grid_hard, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "grid_hard.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \n",
    "print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\n",
    "print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "#Soft Vote or weighted probabilities w/Tuned Hyperparameters\n",
    "grid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "grid_soft_cv = model_selection.cross_validate(grid_soft, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n",
    "grid_soft.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \n",
    "print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\n",
    "print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd37d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend --quiet\n",
    "#import joblib\n",
    "\n",
    "#joblib.dump(model, 'first_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c675c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_Code</th>\n",
       "      <th>Embarked_Code</th>\n",
       "      <th>Title_Code</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.773973</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass        Age  SibSp  Parch     Fare  Sex_Code  \\\n",
       "0           0       3  22.000000      1      0   7.2500         1   \n",
       "1           1       1  38.000000      1      0  71.2833         0   \n",
       "2           1       3  26.000000      0      0   7.9250         0   \n",
       "3           1       1  35.000000      1      0  53.1000         0   \n",
       "4           0       3  35.000000      0      0   8.0500         1   \n",
       "..        ...     ...        ...    ...    ...      ...       ...   \n",
       "886         0       2  27.000000      0      0  13.0000         1   \n",
       "887         1       1  19.000000      0      0  30.0000         0   \n",
       "888         0       3  21.773973      1      2  23.4500         0   \n",
       "889         1       1  26.000000      0      0  30.0000         1   \n",
       "890         0       3  32.000000      0      0   7.7500         1   \n",
       "\n",
       "     Embarked_Code  Title_Code  Sex_male  Embarked_Q  Embarked_S  \n",
       "0                2           2         1           0           1  \n",
       "1                0           3         0           0           0  \n",
       "2                2           1         0           0           1  \n",
       "3                2           3         0           0           1  \n",
       "4                2           2         1           0           1  \n",
       "..             ...         ...       ...         ...         ...  \n",
       "886              2           4         1           0           1  \n",
       "887              2           1         0           0           1  \n",
       "888              2           1         0           0           1  \n",
       "889              0           2         1           0           0  \n",
       "890              1           2         1           1           0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb85ff28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
      "Best Parameters:  {'max_samples': 0.5, 'n_estimators': 300, 'oob_score': True, 'random_state': 0}\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 300, 'random_state': 0}\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 8, 'n_estimators': 300, 'random_state': 0}\n",
      "Best Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 100, 'random_state': 0}\n",
      "Best Parameters:  {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50, 'random_state': 0}\n",
      "Best Parameters:  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "#decision tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\n",
    "submit_dt = tree.DecisionTreeClassifier()\n",
    "submit_dt = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_dt.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_dt.best_params_) #Best Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_dt.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#bagging w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77990\n",
    "submit_bc = ensemble.BaggingClassifier()\n",
    "submit_bc = model_selection.GridSearchCV(ensemble.BaggingClassifier(), param_grid= {'n_estimators':grid_n_estimator, 'max_samples': grid_ratio, 'oob_score': grid_bool, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_bc.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_bc.best_params_) #Best Parameters:  {'max_samples': 0.25, 'n_estimators': 500, 'oob_score': True, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_bc.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#extra tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\n",
    "submit_etc = ensemble.ExtraTreesClassifier()\n",
    "submit_etc = model_selection.GridSearchCV(ensemble.ExtraTreesClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_etc.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_etc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_etc.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#random foreset w/full dataset modeling submission score: defaults= 0.71291, tuned= 0.73205\n",
    "submit_rfc = ensemble.RandomForestClassifier()\n",
    "submit_rfc = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_rfc.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_rfc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_rfc.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "\n",
    "#ada boosting w/full dataset modeling submission score: defaults= 0.74162, tuned= 0.75119\n",
    "submit_abc = ensemble.AdaBoostClassifier()\n",
    "submit_abc = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid={'n_estimators': grid_n_estimator, 'learning_rate': grid_ratio, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_abc.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_abc.best_params_) #Best Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_abc.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#gradient boosting w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77033\n",
    "submit_gbc = ensemble.GradientBoostingClassifier()\n",
    "submit_gbc = model_selection.GridSearchCV(ensemble.GradientBoostingClassifier(), param_grid={'learning_rate': grid_ratio, 'n_estimators': grid_n_estimator, 'max_depth': grid_max_depth, 'random_state':grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_gbc.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_gbc.best_params_) #Best Parameters:  {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50, 'random_state': 0}\n",
    "#data_val['Survived'] = submit_gbc.predict(data_val[data1_x_bin])\n",
    "\n",
    "#extreme boosting w/full dataset modeling submission score: defaults= 0.73684, tuned= 0.77990\n",
    "submit_xgb = XGBClassifier()\n",
    "submit_xgb = model_selection.GridSearchCV(XGBClassifier(), param_grid= {'learning_rate': grid_learn, 'max_depth': [0,2,4,6,8,10], 'n_estimators': grid_n_estimator, 'seed': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n",
    "submit_xgb.fit(data1[data1_x_bin], data1[Target])\n",
    "print('Best Parameters: ', submit_xgb.best_params_) #Best Parameters:  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0}\n",
    "#data_val['Survived'] = submit_xgb.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#hard voting classifier w/full dataset modeling submission score: defaults= 0.75598, tuned = 0.77990\n",
    "#data_val['Survived'] = vote_hard.predict(data_val[data1_x_bin])\n",
    "#data_val['Survived'] = grid_hard.predict(data_val[data1_x_bin])\n",
    "\n",
    "\n",
    "#soft voting classifier w/full dataset modeling submission score: defaults= 0.73684, tuned = 0.74162\n",
    "#data_val['Survived'] = vote_soft.predict(data_val[data1_x_bin])\n",
    "#data_val['Survived'] = grid_soft.predict(data_val[data1_x_bin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87edc8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\dhj98\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['grid_soft.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install mlxtend --quiet\n",
    "import joblib\n",
    "\n",
    "joblib.dump(submit_dt, 'DecisionTree.pkl')\n",
    "joblib.dump(submit_bc, 'bagging.pkl')\n",
    "joblib.dump(submit_etc, 'ExtraTree.pkl')\n",
    "joblib.dump(submit_rfc, 'RandomForest.pkl')\n",
    "joblib.dump(submit_abc, 'AdaBoosting.pkl')\n",
    "joblib.dump(submit_etc, 'ExtremeBoosting.pkl')\n",
    "joblib.dump(submit_gbc, 'GradientBoosing.pkl')\n",
    "joblib.dump(vote_soft, 'vote_soft.pkl')\n",
    "joblib.dump(grid_soft, 'grid_soft.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afaecb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree = joblib.load('DecisionTree.pkl')\n",
    "pred = DecisionTree.predict(data_val[data1_x_bin])\n",
    "pred[0] => 사망"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "357.865px",
    "left": "1406.28px",
    "right": "20px",
    "top": "52.9306px",
    "width": "651.771px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
